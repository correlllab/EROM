{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from aspire.homog_utils import vec_unit\n",
    "\n",
    "from scipy.spatial import KDTree  \n",
    "\n",
    "def get_cube( sideLen, homog ):\n",
    "    \"\"\" Return a 3x36 array of cube vertices, transformed by `homog` \"\"\"\n",
    "    hl = sideLen/2.0\n",
    "    #                Front\n",
    "    vrts = np.array([[-hl,-hl, hl, 1.0],\n",
    "                     [+hl,-hl, hl, 1.0],\n",
    "                     [+hl,+hl, hl, 1.0],\n",
    "         \n",
    "                     [+hl,+hl, hl, 1.0],\n",
    "                     [-hl,+hl, hl, 1.0],\n",
    "                     [-hl,-hl, hl, 1.0],\n",
    "         \n",
    "                     # Back\n",
    "                     [+hl,-hl,-hl, 1.0],\n",
    "                     [-hl,-hl,-hl, 1.0],\n",
    "                     [-hl,+hl,-hl, 1.0],\n",
    "         \n",
    "                     [-hl,+hl,-hl, 1.0],\n",
    "                     [+hl,+hl,-hl, 1.0],\n",
    "                     [+hl,-hl,-hl, 1.0],\n",
    "         \n",
    "                     # Right\n",
    "                     [+hl,-hl,+hl, 1.0],\n",
    "                     [+hl,-hl,-hl, 1.0],\n",
    "                     [+hl,+hl,-hl, 1.0],\n",
    "         \n",
    "                     [+hl,+hl,-hl, 1.0],\n",
    "                     [+hl,+hl,+hl, 1.0],\n",
    "                     [+hl,-hl,+hl, 1.0],\n",
    "         \n",
    "                     # Left\n",
    "                     [-hl,-hl,-hl, 1.0],\n",
    "                     [-hl,-hl,+hl, 1.0],\n",
    "                     [-hl,+hl,+hl, 1.0],\n",
    "         \n",
    "                     [-hl,+hl,+hl, 1.0],\n",
    "                     [-hl,+hl,-hl, 1.0],\n",
    "                     [-hl,-hl,-hl, 1.0],\n",
    "         \n",
    "                     # Top\n",
    "                     [-hl,+hl,+hl, 1.0],\n",
    "                     [+hl,+hl,+hl, 1.0],\n",
    "                     [+hl,+hl,-hl, 1.0],\n",
    "         \n",
    "                     [+hl,+hl,-hl, 1.0],\n",
    "                     [-hl,+hl,-hl, 1.0],\n",
    "                     [-hl,+hl,+hl, 1.0],\n",
    "         \n",
    "                     # Bottom\n",
    "                     [-hl,-hl,-hl, 1.0],\n",
    "                     [+hl,-hl,-hl, 1.0],\n",
    "                     [+hl,-hl,+hl, 1.0],\n",
    "         \n",
    "                     [+hl,-hl,+hl, 1.0],\n",
    "                     [-hl,-hl,+hl, 1.0],\n",
    "                     [-hl,-hl,-hl, 1.0],])\n",
    "    return np.dot( homog, vrts.transpose() )[:3,:].transpose()\n",
    "\n",
    "\n",
    "def get_normals_diameters_and_centers( vertTriples : np.ndarray ):\n",
    "    \"\"\" Return the normal (and \"diameter\") at each vertex, assuming every three vertices form a triangle \"\"\"\n",
    "    # NOTE: Diameters will be used a distance heuristic\n",
    "    # NOTE: This function outputs some distances 3 times in order to make the Numpy operations nice\n",
    "    rtnNrm = np.ones( vertTriples.shape )\n",
    "    rtnCen = np.ones( vertTriples.shape )\n",
    "    rtnDia = np.ones( len( vertTriples ) )\n",
    "    for i in range( 0, len( vertTriples ), 3 ):\n",
    "        p0 = vertTriples[i  ,:3]\n",
    "        p1 = vertTriples[i+1,:3]\n",
    "        p2 = vertTriples[i+2,:3]\n",
    "        v0 = np.subtract( p1, p0 )\n",
    "        v1 = np.subtract( p2, p1 )\n",
    "        v2 = np.subtract( p0, p2 )\n",
    "        mx = np.max( [np.linalg.norm( v0 ), np.linalg.norm( v1 ), np.linalg.norm( v2 ),] )\n",
    "        ni = vec_unit( np.cross( v0, v1 ) )\n",
    "        ci = ( p0 + p1 + p2 ) / 3.0\n",
    "        rtnNrm[ i:i+3, :3 ] = [ni, ni, ni,]\n",
    "        rtnCen[ i:i+3, :3 ] = [ci, ci, ci,]\n",
    "        rtnDia[ i:i+3 ] = [mx, mx, mx,]\n",
    "    return rtnNrm, rtnDia, rtnCen\n",
    "\n",
    "\n",
    "def min_dist_to_mesh( q, verts, norms, diams, cntrs ):\n",
    "    \"\"\" Given a list of triangle verts, Return the least distance from `q` to the mesh, HACK: We don't actually care if it's very accurate! \"\"\"\n",
    "    # HACK: This function uses a distance heuristic to determine if the point distance or plane distance is correct\n",
    "    # HACK: This function does NOT take into account the distance to the triangle edge in the case that it is the least distance\n",
    "    # NOTE: This function computes some distances 3 times in order to make the Numpy operations nice\n",
    "    factr = 1.5 # Bubble factor\n",
    "    Npnts = len( verts )\n",
    "    diffs = np.subtract( verts, q )\n",
    "    cenDf = np.subtract( cntrs, q )\n",
    "    cenDs = np.linalg.norm( cenDf, axis = 1 )\n",
    "    plnDs = np.sum( norms * diffs, axis = 1, keepdims = True ) # https://stackoverflow.com/q/62500584\n",
    "    pntDs = np.linalg.norm( diffs, axis = 1 ) # https://stackoverflow.com/a/7741976\n",
    "    dMin  = 1e9\n",
    "    for i in range( Npnts ):\n",
    "        # HACK: CHOOSE POINT DISTANCE IF OUTSIDE OF BUBBLE, CHOOSE PLANE DISTANCE IF INSIDE BUBBLE\n",
    "        if (cenDs[i,0] > (diams[i]*factr)):\n",
    "            dMin = min( dMin, pntDs[i,0] )\n",
    "        else:\n",
    "            dMin = min( dMin, abs( plnDs[i,0] ) )\n",
    "    return dMin\n",
    "\n",
    "\n",
    "def ransac(points, sideLen, max_iterations=1000, inlier_threshold=0.05, seed=None):\n",
    "    \"\"\"\n",
    "    RANSAC algorithm to estimate the pose of a cube given noisy point cloud data.\n",
    "    Args:\n",
    "        points (np.ndarray): Nx3 array of point cloud data.\n",
    "        sideLen (float): Length of the cube's sides.\n",
    "        max_iterations (int): Number of RANSAC iterations.\n",
    "        inlier_threshold (float): Distance threshold to consider a point as an inlier.\n",
    "        seed (int, optional): Random seed for reproducibility.\n",
    "    Returns:\n",
    "        best_pose (np.ndarray): 4x4 transformation matrix of the estimated cube pose.\n",
    "    \"\"\"\n",
    "    best_pose = None\n",
    "    max_inliers = 0\n",
    "\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    # Precompute the canonical cube model points (e.g., the 8 corners)\n",
    "    canonical_cube_points = get_cube(sideLen, np.eye(4)).T  # 8x3 array\n",
    "\n",
    "    for _ in range(max_iterations):\n",
    "        # Randomly sample 3 non-colinear points from the data\n",
    "        sample_indices = np.random.choice(len(points), size=3, replace=False)\n",
    "        sampled_points = points[sample_indices]\n",
    "\n",
    "        # Check for colinearity\n",
    "        if np.linalg.matrix_rank(sampled_points - sampled_points[0]) < 3:\n",
    "            continue  # Skip iteration if points are colinear\n",
    "\n",
    "        # Corresponding points on the cube model (e.g., select 3 non-colinear corners)\n",
    "        model_indices = np.random.choice(len(canonical_cube_points), size=3, replace=False)\n",
    "        model_points = canonical_cube_points[model_indices]\n",
    "\n",
    "\n",
    "        # Estimate pose using the Kabsch algorithm\n",
    "        try:\n",
    "            R, t = estimate_rigid_transform(model_points, sampled_points)\n",
    "        except np.linalg.LinAlgError:\n",
    "            continue  # Skip if SVD fails\n",
    "\n",
    "        # Construct the transformation matrix\n",
    "        pose = np.eye(4)\n",
    "        pose[:3, :3] = R\n",
    "        pose[:3, 3] = t\n",
    "\n",
    "        # Transform the canonical cube model points to the estimated pose\n",
    "        transformed_model_points = (R @ canonical_cube_points.T + t[:, np.newaxis]).T\n",
    "\n",
    "        # Compute distances from all data points to the transformed cube surface\n",
    "        distances = compute_point_to_model_distances(points, transformed_model_points, sideLen)\n",
    "\n",
    "        # Count inliers\n",
    "        inliers = np.sum(distances < inlier_threshold)\n",
    "\n",
    "        # Update best pose if current pose has more inliers\n",
    "        if inliers > max_inliers:\n",
    "            max_inliers = inliers\n",
    "            best_pose = pose\n",
    "\n",
    "    return best_pose\n",
    "\n",
    "def icp(points, sideLen, initial_pose=None, max_iterations=50, convergence_threshold=1e-4):\n",
    "    \"\"\"\n",
    "    ICP algorithm to refine the pose of a cube given an initial estimate.\n",
    "    Args:\n",
    "        points (np.ndarray): Nx3 array of point cloud data.\n",
    "        sideLen (float): Length of the cube's sides.\n",
    "        initial_pose (np.ndarray): 4x4 initial transformation matrix.\n",
    "        max_iterations (int): Maximum number of ICP iterations.\n",
    "        convergence_threshold (float): Threshold for convergence.\n",
    "    Returns:\n",
    "        pose (np.ndarray): Refined 4x4 transformation matrix of the cube pose.\n",
    "    \"\"\"\n",
    "    # Initialize the pose\n",
    "    pose = np.eye(4) if initial_pose is None else initial_pose\n",
    "\n",
    "    # Generate dense points on the cube surface for better correspondences\n",
    "    model_points = generate_cube_surface_points(sideLen, num_points=1000)  # Nx3 array\n",
    "\n",
    "    for iteration in range(max_iterations):\n",
    "        # Transform model points to the current pose\n",
    "        transformed_model_points = (pose[:3, :3] @ model_points.T + pose[:3, 3][:, np.newaxis]).T\n",
    "\n",
    "        # Build KDTree for the data points\n",
    "        kdtree = KDTree(points)\n",
    "\n",
    "        # Find closest data point for each model point\n",
    "        distances, indices = kdtree.query(transformed_model_points)\n",
    "        closest_data_points = points[indices]\n",
    "\n",
    "        # Apply outlier rejection (e.g., keep correspondences within a threshold)\n",
    "        valid_indices = distances < convergence_threshold * 10  # Arbitrary factor, maybe we can use diff outlier rejection method, this is just placeholder\n",
    "        if np.sum(valid_indices) == 0:\n",
    "            break  # No valid correspondences\n",
    "\n",
    "        # Select valid correspondences\n",
    "        src_points = transformed_model_points[valid_indices]\n",
    "        dst_points = closest_data_points[valid_indices]\n",
    "\n",
    "        # Estimate transformation between src_points and dst_points\n",
    "        R, t = estimate_rigid_transform(src_points, dst_points)\n",
    "\n",
    "        # Update pose\n",
    "        delta_pose = np.eye(4)\n",
    "        delta_pose[:3, :3] = R\n",
    "        delta_pose[:3, 3] = t\n",
    "        pose = delta_pose @ pose\n",
    "\n",
    "        # Check convergence\n",
    "        mean_error = np.mean(distances[valid_indices])\n",
    "        if mean_error < convergence_threshold:\n",
    "            break\n",
    "\n",
    "    return pose\n",
    "\n",
    "def estimate_rigid_transform(A, B):\n",
    "    \"\"\"\n",
    "    Estimate the optimal rotation and translation between two sets of points.\n",
    "    Args:\n",
    "        A (np.ndarray): Nx3 array of source points.\n",
    "        B (np.ndarray): Nx3 array of destination points.\n",
    "    Returns:\n",
    "        R (np.ndarray): 3x3 rotation matrix.\n",
    "        t (np.ndarray): 3x1 translation vector.\n",
    "    \"\"\"\n",
    "    # Compute centroids\n",
    "    centroid_A = np.mean(A, axis=0)\n",
    "    centroid_B = np.mean(B, axis=0)\n",
    "\n",
    "    # Subtract centroids\n",
    "    AA = A - centroid_A\n",
    "    BB = B - centroid_B\n",
    "\n",
    "    # Compute covariance matrix\n",
    "    H = AA.T @ BB\n",
    "\n",
    "    # SVD decomposition\n",
    "    U, S, Vt = np.linalg.svd(H)\n",
    "    R = Vt.T @ U.T\n",
    "\n",
    "    # Correct reflection issue\n",
    "    if np.linalg.det(R) < 0:\n",
    "        Vt[-1, :] *= -1\n",
    "        R = Vt.T @ U.T\n",
    "\n",
    "    # Compute translation\n",
    "    t = centroid_B - R @ centroid_A\n",
    "\n",
    "    return R, t\n",
    "\n",
    "def compute_point_to_model_distances(points, model_points, sideLen):\n",
    "    \"\"\"\n",
    "    Compute distances from data points to the cube model surface.\n",
    "    Args:\n",
    "        points (np.ndarray): Nx3 array of data points.\n",
    "        model_points (np.ndarray): Mx3 array of transformed model points.\n",
    "        sideLen (float): Length of the cube's sides.\n",
    "    Returns:\n",
    "        distances (np.ndarray): Nx1 array of distances.\n",
    "    \"\"\"\n",
    "    # Build KDTree for the model points\n",
    "    kdtree = KDTree(model_points)\n",
    "\n",
    "    # Find closest model point for each data point\n",
    "    distances, _ = kdtree.query(points)\n",
    "\n",
    "    return distances\n",
    "\n",
    "def generate_cube_surface_points(sideLen, num_points=1000):\n",
    "    \"\"\"\n",
    "    Generate a dense set of points on the surface of a cube.\n",
    "    Args:\n",
    "        sideLen (float): Length of the cube's sides.\n",
    "        num_points (int): Number of points to generate.\n",
    "    Returns:\n",
    "        points (np.ndarray): Nx3 array of points on the cube surface.\n",
    "    \"\"\"\n",
    "    hl = sideLen / 2.0\n",
    "    # Generate points on each face\n",
    "    face_points = []\n",
    "    for axis in range(3):\n",
    "        for sign in [-1, 1]:\n",
    "            coords = np.random.uniform(-hl, hl, size=(num_points // 6, 2))\n",
    "            points = np.zeros((num_points // 6, 3))\n",
    "            points[:, axis] = sign * hl\n",
    "            other_axes = [i for i in range(3) if i != axis]\n",
    "            points[:, other_axes] = coords\n",
    "            face_points.append(points)\n",
    "    return np.vstack(face_points)\n",
    "\n",
    "def estimate_cube_pose(points, sideLen, method=\"RANSAC\", **kwargs):\n",
    "    \"\"\"\n",
    "    Estimate the cube pose using the specified method (RANSAC or ICP).\n",
    "    Args:\n",
    "        points (np.ndarray): Nx3 array of point cloud data.\n",
    "        sideLen (float): Length of the cube's sides.\n",
    "        method (str): Estimation method ('RANSAC' or 'ICP').\n",
    "        kwargs: Additional arguments for the estimation methods.\n",
    "    Returns:\n",
    "        pose (np.ndarray): 4x4 transformation matrix of the cube pose.\n",
    "    \"\"\"\n",
    "    if method.upper() == \"RANSAC\":\n",
    "        return ransac(points, sideLen, **kwargs)\n",
    "    elif method.upper() == \"ICP\":\n",
    "        return icp(points, sideLen, **kwargs)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method '{method}'. Use 'RANSAC' or 'ICP'.\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate synthetic test points (e.g., a cube with noise)\n",
    "    cube_side = 1.0\n",
    "    true_pose = np.eye(4)\n",
    "    true_pose[:3, 3] = [0.5, 0.5, 0.5]\n",
    "    true_pose[:3, :3] = np.array([\n",
    "        [0, -1, 0],\n",
    "        [1,  0, 0],\n",
    "        [0,  0, 1]\n",
    "    ])  # Add some rotation\n",
    "\n",
    "    # Generate dense points on the cube surface\n",
    "    cube_points = generate_cube_surface_points(cube_side, num_points=2000)\n",
    "    # Transform the cube points to the true pose\n",
    "    cube_points = (true_pose[:3, :3] @ cube_points.T + true_pose[:3, 3][:, np.newaxis]).T\n",
    "    # Add Gaussian noise\n",
    "    noisy_points = cube_points + np.random.normal(0, 0.01, cube_points.shape)\n",
    "\n",
    "    # Test RANSAC\n",
    "    ransac_pose = estimate_cube_pose(noisy_points, cube_side, method=\"RANSAC\", max_iterations=1000, inlier_threshold=0.05)\n",
    "\n",
    "    # Refine with ICP using RANSAC result as initial pose\n",
    "    icp_pose = estimate_cube_pose(noisy_points, cube_side, method=\"ICP\", initial_pose=ransac_pose, max_iterations=50)\n",
    "\n",
    "    print(\"True Pose:\")\n",
    "    print(true_pose)\n",
    "    print(\"\\nRANSAC Estimated Pose:\")\n",
    "    print(ransac_pose)\n",
    "    print(\"\\nICP Refined Pose:\")\n",
    "    print(icp_pose)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
